"""
Telegram bot handlers.
"""

import json
import asyncio
import time
from pathlib import Path
from aiogram import Router, F
from aiogram.types import Message, CallbackQuery
from aiogram.filters import Command
import sys

sys.path.insert(0, str(Path(__file__).parent.parent))

from config import SESSIONS_DIR, DATA_DIR, LLM_MODEL, AVAILABLE_MODELS, SENTIMENT_TOP_K, SENTIMENT_MAX_CONCURRENT_REQUESTS
from rag.search import search, format_search_results
from llm.prompts import build_system_prompt, build_user_prompt, get_available_speakers
from llm.client import chat
from bot.keyboards import get_speaker_keyboard, get_menu_keyboard
from logging_system import get_interaction_logger
from sentiment import SentimentAnalyzer, create_sentiment_chart

router = Router()


def split_message(text: str, max_length: int = 4096) -> list[str]:
    """
    Split long message into chunks respecting Telegram's 4096 character limit.

    Args:
        text: Text to split
        max_length: Maximum length per chunk (default 4096 for Telegram)

    Returns:
        List of text chunks
    """
    if len(text) <= max_length:
        return [text]

    chunks = []
    current_chunk = ""

    for line in text.split('\n'):
        # If adding this line would exceed limit, save current chunk and start new one
        if len(current_chunk) + len(line) + 1 > max_length:
            if current_chunk:
                chunks.append(current_chunk.rstrip())
                current_chunk = ""

        # If single line is too long, split it by words
        if len(line) > max_length:
            words = line.split(' ')
            for word in words:
                if len(current_chunk) + len(word) + 1 > max_length:
                    if current_chunk:
                        chunks.append(current_chunk.rstrip())
                    current_chunk = word + " "
                else:
                    current_chunk += word + " "
        else:
            current_chunk += line + "\n"

    # Add remaining text
    if current_chunk:
        chunks.append(current_chunk.rstrip())

    return chunks


# Session management
def load_session(user_id: int) -> dict:
    """Load user session from file."""
    session_path = SESSIONS_DIR / f"{user_id}.json"
    if session_path.exists():
        with open(session_path, 'r', encoding='utf-8') as f:
            session = json.load(f)
            # Add time_filter if not present (backward compatibility)
            if "time_filter" not in session:
                session["time_filter"] = "balanced"
            return session
    return {
        "speaker": None,
        "model": None,
        "history": [],
        "waiting_for_model": False,
        "waiting_for_dates": False,
        "time_filter": "balanced"  # Default: temporal decay mode
    }


def save_session(user_id: int, session: dict):
    """Save user session to file."""
    session_path = SESSIONS_DIR / f"{user_id}.json"
    with open(session_path, 'w', encoding='utf-8') as f:
        json.dump(session, f, ensure_ascii=False, indent=2)


def check_index_exists() -> bool:
    """Check if RAG index exists."""
    return (DATA_DIR / "embeddings.npy").exists() and (DATA_DIR / "chunks.json").exists()


# Command handlers
@router.message(Command("start"))
async def cmd_start(message: Message):
    """Handle /start command."""
    if not check_index_exists():
        await message.answer(
            "–ò–Ω–¥–µ–∫—Å –Ω–µ –Ω–∞–π–¥–µ–Ω. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞:\n"
            "`python scripts/index_podcasts.py`",
            parse_mode="Markdown"
        )
        return

    speakers = get_available_speakers()
    await message.answer(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç –¥–ª—è –æ–±—â–µ–Ω–∏—è —Å –ø–µ—Ä—Å–æ–Ω–∞–∂–∞–º–∏ –ø–æ–¥–∫–∞—Å—Ç–∞ Drops Capital.\n\n"
        "–í—ã–±–µ—Ä–∏—Ç–µ, —Å –∫–µ–º —Ö–æ—Ç–∏—Ç–µ –ø–æ–æ–±—â–∞—Ç—å—Å—è:",
        reply_markup=get_speaker_keyboard(speakers)
    )


@router.message(Command("switch"))
async def cmd_switch(message: Message):
    """Handle /switch command - change speaker."""
    speakers = get_available_speakers()
    await message.answer(
        "–í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–≤–æ–≥–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞:",
        reply_markup=get_speaker_keyboard(speakers)
    )


@router.message(Command("clear"))
async def cmd_clear(message: Message):
    """Handle /clear command - clear history."""
    session = load_session(message.from_user.id)
    session["history"] = []
    save_session(message.from_user.id, session)

    speaker = session.get("speaker")
    if speaker:
        await message.answer(f"–ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞. –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—â–µ–Ω–∏–µ —Å {speaker}.")
    else:
        await message.answer("–ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞.")


@router.message(Command("help"))
async def cmd_help(message: Message):
    """Show help message with all commands."""
    help_text = (
        "<b>üìö –°–ø—Ä–∞–≤–∫–∞ –ø–æ –∫–æ–º–∞–Ω–¥–∞–º</b>\n\n"
        "<b>–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:</b>\n"
        "/start - –Ω–∞—á–∞—Ç—å —Ä–∞–±–æ—Ç—É —Å –±–æ—Ç–æ–º\n"
        "/switch - —Å–º–µ–Ω–∏—Ç—å –ø–µ—Ä—Å–æ–Ω–∞–∂–∞\n"
        "/clear - –æ—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞\n"
        "/model - –≤—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å LLM\n"
        "/menu - –ø–æ–∫–∞–∑–∞—Ç—å –º–µ–Ω—é\n"
        "/help - –ø–æ–∫–∞–∑–∞—Ç—å —ç—Ç—É —Å–ø—Ä–∞–≤–∫—É\n\n"
        "<b>‚è± –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º:</b>\n"
        "/time_mode - –ø–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º\n"
        "/recent - —Ç–æ–ª—å–∫–æ —Å–≤–µ–∂–∏–µ (2 –Ω–µ–¥–µ–ª–∏) üî•\n"
        "/balanced - –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é) ‚öñÔ∏è\n"
        "/historical - –≤—Å—è –∏—Å—Ç–æ—Ä–∏—è üìö\n"
        "/date_range - –≤—ã–±—Ä–∞—Ç—å –ø–µ—Ä–∏–æ–¥ üìÖ\n\n"
        "<b>üìä –ê–Ω–∞–ª–∏–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è –º–Ω–µ–Ω–∏–π:</b>\n"
        "/sentiment <—Ç–µ–º–∞> - –∞–Ω–∞–ª–∏–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è –º–Ω–µ–Ω–∏–π –æ —Ç–µ–º–µ\n"
        "–ü—Ä–∏–º–µ—Ä: /sentiment –±–∏—Ç–∫–æ–∏–Ω\n"
        "–ü—Ä–∏–º–µ—Ä: /sentiment eigen layer\n\n"
        "<b>–†–µ–∂–∏–º—ã –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞:</b>\n"
        "‚Ä¢ <b>Recent</b> - –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ø–æ–¥–∫–∞—Å—Ç—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 –Ω–µ–¥–µ–ª–∏\n"
        "‚Ä¢ <b>Balanced</b> - –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä—É–µ—Ç —Å–≤–µ–∂–∏–µ –º–Ω–µ–Ω–∏—è (~70%), –Ω–æ —É—á–∏—Ç—ã–≤–∞–µ—Ç –∏ –∏—Å—Ç–æ—Ä–∏—é (~30%)\n"
        "‚Ä¢ <b>Historical</b> - –≤—Å–µ –ø–æ–¥–∫–∞—Å—Ç—ã –∏–º–µ—é—Ç —Ä–∞–≤–Ω—ã–π –≤–µ—Å, —Ö–æ—Ä–æ—à–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π –º–Ω–µ–Ω–∏–π\n"
        "‚Ä¢ <b>Date Range</b> - –≤—ã–±—Ä–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –¥–ª—è –ø–æ–∏—Å–∫–∞\n"
    )
    await message.answer(help_text, parse_mode="HTML")


@router.message(Command("menu"))
async def cmd_menu(message: Message):
    """Show menu with actions."""
    await message.answer(
        "–ú–µ–Ω—é:",
        reply_markup=get_menu_keyboard()
    )


@router.message(Command("model"))
async def cmd_model(message: Message):
    """Handle /model command - show available models."""
    # Build model list message
    model_list = "–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ LLM:\n\n"
    models = list(AVAILABLE_MODELS.items())
    for i, (model_id, description) in enumerate(models, 1):
        model_list += f"{i}. {description}\n"

    model_list += "\n–û—Ç–ø—Ä–∞–≤—å—Ç–µ –Ω–æ–º–µ—Ä –º–æ–¥–µ–ª–∏ –¥–ª—è –≤—ã–±–æ—Ä–∞ (1-2)"

    # Set waiting flag
    session = load_session(message.from_user.id)
    session["waiting_for_model"] = True
    save_session(message.from_user.id, session)

    await message.answer(model_list)


@router.message(Command("recent"))
async def cmd_recent(message: Message):
    """Switch to recent mode (last 2 weeks only)."""
    user_id = message.from_user.id
    session = load_session(user_id)

    session["time_filter"] = "recent"
    save_session(user_id, session)

    await message.answer(
        "‚úÖ –†–µ–∂–∏–º: <b>–°–≤–µ–∂–∏–µ –ø–æ–¥–∫–∞—Å—Ç—ã</b>\n"
        "–ü–æ–∫–∞–∑—ã–≤–∞—é —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 –Ω–µ–¥–µ–ª–∏.\n\n"
        "–î—Ä—É–≥–∏–µ —Ä–µ–∂–∏–º—ã:\n"
        "/balanced - –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π (default)\n"
        "/historical - –≤—Å—è –∏—Å—Ç–æ—Ä–∏—è\n"
        "/date_range - –≤—ã–±—Ä–∞—Ç—å –ø–µ—Ä–∏–æ–¥",
        parse_mode="HTML"
    )


@router.message(Command("balanced"))
async def cmd_balanced(message: Message):
    """Switch to balanced mode (temporal decay)."""
    user_id = message.from_user.id
    session = load_session(user_id)

    session["time_filter"] = "balanced"
    save_session(user_id, session)

    await message.answer(
        "‚úÖ –†–µ–∂–∏–º: <b>–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π</b> (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)\n"
        "~70% —Å–≤–µ–∂–∏–µ –º–Ω–µ–Ω–∏—è (2 –Ω–µ–¥–µ–ª–∏) + ~30% –∏—Å—Ç–æ—Ä–∏—è.\n"
        "–°—Ç–∞—Ä—ã–µ –º–Ω–µ–Ω–∏—è –Ω–µ –∏—Å—á–µ–∑–∞—é—Ç, –Ω–æ –ø–æ–Ω–∏–∂–∞—é—Ç—Å—è.",
        parse_mode="HTML"
    )


@router.message(Command("historical"))
async def cmd_historical(message: Message):
    """Switch to historical mode (all history, no decay)."""
    user_id = message.from_user.id
    session = load_session(user_id)

    session["time_filter"] = "historical"
    save_session(user_id, session)

    await message.answer(
        "‚úÖ –†–µ–∂–∏–º: <b>–í—Å—è –∏—Å—Ç–æ—Ä–∏—è</b>\n"
        "–í—Å–µ –ø–æ–¥–∫–∞—Å—Ç—ã –∏–º–µ—é—Ç —Ä–∞–≤–Ω—ã–π –≤–µ—Å.\n"
        "–ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ —Ç–∏–ø–∞:\n"
        "\"–ö–∞–∫ –º–µ–Ω—è–ª–æ—Å—å –º–Ω–µ–Ω–∏–µ –æ BTC –∑–∞ –≥–æ–¥?\"",
        parse_mode="HTML"
    )


@router.message(Command("date_range"))
async def cmd_date_range(message: Message):
    """Initiate custom date range selection."""
    user_id = message.from_user.id
    session = load_session(user_id)

    session["waiting_for_dates"] = True
    save_session(user_id, session)

    await message.answer(
        "üìÖ –û—Ç–ø—Ä–∞–≤—å—Ç–µ –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n"
        "<code>YYYY-MM-DD YYYY-MM-DD</code>\n\n"
        "–ü—Ä–∏–º–µ—Ä: <code>2025-12-01 2026-01-15</code>\n\n"
        "–ò–ª–∏ /cancel –¥–ª—è –æ—Ç–º–µ–Ω—ã",
        parse_mode="HTML"
    )


@router.message(Command("time_mode"))
async def cmd_time_mode(message: Message):
    """Show current time filter mode."""
    user_id = message.from_user.id
    session = load_session(user_id)

    time_filter = session.get("time_filter", "balanced")

    # Format mode description
    mode_descriptions = {
        "recent": "üî• –°–≤–µ–∂–∏–µ –ø–æ–¥–∫–∞—Å—Ç—ã (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 –Ω–µ–¥–µ–ª–∏)",
        "balanced": "‚öñÔ∏è –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π (70% —Å–≤–µ–∂–∏–µ / 30% –∏—Å—Ç–æ—Ä–∏—è)",
        "historical": "üìö –í—Å—è –∏—Å—Ç–æ—Ä–∏—è (–±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞)"
    }

    if isinstance(time_filter, dict):
        description = f"üìÖ –ö–∞—Å—Ç–æ–º–Ω—ã–π –ø–µ—Ä–∏–æ–¥: {time_filter['start']} ‚Äî {time_filter['end']}"
    else:
        description = mode_descriptions.get(time_filter, "‚öñÔ∏è –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π")

    await message.answer(
        f"<b>–¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º:</b>\n{description}\n\n"
        "–ò–∑–º–µ–Ω–∏—Ç—å: /recent | /balanced | /historical | /date_range",
        parse_mode="HTML"
    )


@router.message(Command("sentiment"))
async def cmd_sentiment(message: Message):
    """Analyze sentiment trends for an entity."""
    from aiogram.types import BufferedInputFile
    from sentiment.exporter import export_sentiment_to_txt
    from datetime import datetime

    # Parse command arguments
    args = message.text.split(maxsplit=1)
    if len(args) < 2:
        await message.answer(
            "üìä <b>–ê–Ω–∞–ª–∏–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è –º–Ω–µ–Ω–∏–π</b>\n\n"
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:\n"
            "<code>/sentiment &lt;—Ç–µ–º–∞&gt;</code>\n\n"
            "–ü—Ä–∏–º–µ—Ä—ã:\n"
            "‚Ä¢ <code>/sentiment –±–∏—Ç–∫–æ–∏–Ω</code>\n"
            "‚Ä¢ <code>/sentiment eigen layer</code>\n"
            "‚Ä¢ <code>/sentiment –∞–ª—å—Ç–∫–æ–∏–Ω—ã</code>\n\n"
            "–ë–æ—Ç –Ω–∞–π–¥–µ—Ç –≤—Å–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —Ç–µ–º—ã –≤ –ø–æ–¥–∫–∞—Å—Ç–∞—Ö, "
            "–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–Ω–µ–Ω–∏—è —Å–ø–∏–∫–µ—Ä–æ–≤ –∏ –ø–æ–∫–∞–∂–µ—Ç –≥—Ä–∞—Ñ–∏–∫ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤–æ –≤—Ä–µ–º–µ–Ω–∏.",
            parse_mode="HTML"
        )
        return

    entity = args[1].strip()

    # Show processing message
    processing_msg = await message.answer(
        f"üìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –º–Ω–µ–Ω–∏—è –æ '{entity}'...\n"
        f"‚ö° –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: –¥–æ {SENTIMENT_MAX_CONCURRENT_REQUESTS} –∑–∞–ø—Ä–æ—Å–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ\n"
        "–≠—Ç–æ –∑–∞–π–º–µ—Ç ~30-60 —Å–µ–∫—É–Ω–¥...",
        parse_mode="HTML"
    )

    try:
        # Run async analysis (no executor needed)
        analyzer = SentimentAnalyzer()
        sentiments = await analyzer.analyze_entity_async(
            entity=entity,
            top_k=SENTIMENT_TOP_K,  # Configurable via SENTIMENT_TOP_K env variable
            max_concurrent=SENTIMENT_MAX_CONCURRENT_REQUESTS
        )

        if not sentiments:
            await processing_msg.edit_text(
                f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –æ '{entity}' –≤ –ø–æ–¥–∫–∞—Å—Ç–∞—Ö.\n\n"
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫—É –∏–ª–∏ —Ç–µ–º—É.",
                parse_mode="HTML"
            )
            return

        # Generate text summary
        summary = analyzer.summarize_trend(sentiments)

        # Generate chart and TXT export
        try:
            # Create chart
            chart_buffer = create_sentiment_chart(sentiments, entity)
            photo = BufferedInputFile(chart_buffer.getvalue(), filename=f"sentiment_{entity}.png")

            # Create TXT report
            txt_buffer = export_sentiment_to_txt(sentiments, entity)
            txt_filename = f"sentiment_report_{entity}_{datetime.now().strftime('%Y%m%d_%H%M')}.txt"
            txt_file = BufferedInputFile(txt_buffer.getvalue(), filename=txt_filename)

            # Send chart
            await message.answer_photo(photo=photo, caption=f"üìä –ì—Ä–∞—Ñ–∏–∫ –∞–Ω–∞–ª–∏–∑–∞ –º–Ω–µ–Ω–∏–π: {entity}")

            # Send TXT report
            await message.answer_document(document=txt_file, caption="üìÑ –ü–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç —Å –ø–æ–ª–Ω—ã–º–∏ —Ç–µ–∫—Å—Ç–∞–º–∏")

            # Send summary (split if too long)
            summary_chunks = split_message(summary, max_length=4096)
            for chunk in summary_chunks:
                await message.answer(chunk, parse_mode="HTML")

            # Delete processing message
            await processing_msg.delete()

        except Exception as export_error:
            # Fallback: send at least chart and summary if TXT export fails
            print(f"TXT export failed: {export_error}")
            try:
                chart_buffer = create_sentiment_chart(sentiments, entity)
                photo = BufferedInputFile(chart_buffer.getvalue(), filename=f"sentiment_{entity}.png")
                await message.answer_photo(photo=photo)

                # Send summary (split if too long)
                summary_chunks = split_message(summary, max_length=4096)
                for chunk in summary_chunks:
                    await message.answer(chunk, parse_mode="HTML")

                await processing_msg.delete()
            except Exception as chart_error:
                # If chart also fails, still send text summary (split if needed)
                error_msg = f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫: {chart_error}"
                summary_with_error = f"{summary}\n\n{error_msg}"

                # Split and send
                chunks = split_message(summary_with_error, max_length=4096)
                await processing_msg.edit_text(chunks[0], parse_mode="HTML")

                # Send remaining chunks as separate messages
                for chunk in chunks[1:]:
                    await message.answer(chunk, parse_mode="HTML")

    except Exception as e:
        await processing_msg.edit_text(
            f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {e}\n\n"
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥—É—é —Ç–µ–º—É.",
            parse_mode="HTML"
        )
        import traceback
        print(f"Sentiment analysis error: {traceback.format_exc()}")


@router.message(Command("cancel"))
async def cmd_cancel(message: Message):
    """Cancel current operation."""
    user_id = message.from_user.id
    session = load_session(user_id)

    if session.get("waiting_for_dates"):
        session["waiting_for_dates"] = False
        save_session(user_id, session)
        await message.answer("–û—Ç–º–µ–Ω–µ–Ω–æ.")
    elif session.get("waiting_for_model"):
        session["waiting_for_model"] = False
        save_session(user_id, session)
        await message.answer("–û—Ç–º–µ–Ω–µ–Ω–æ.")
    else:
        await message.answer("–ù–µ—á–µ–≥–æ –æ—Ç–º–µ–Ω—è—Ç—å.")


# Callback handlers
@router.callback_query(F.data.startswith("speaker:"))
async def callback_speaker(callback: CallbackQuery):
    """Handle speaker selection."""
    speaker = callback.data.split(":", 1)[1]

    # Save to session
    session = load_session(callback.from_user.id)
    session["speaker"] = speaker
    session["history"] = []  # Clear history on speaker change
    save_session(callback.from_user.id, session)

    await callback.message.edit_text(
        f"–í—ã –≤—ã–±—Ä–∞–ª–∏: {speaker}\n\n"
        f"–¢–µ–ø–µ—Ä—å –º–æ–∂–µ—Ç–µ –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã. –Ø –±—É–¥—É –æ—Ç–≤–µ—á–∞—Ç—å –≤ —Å—Ç–∏–ª–µ {speaker}.\n\n"
        f"<b>–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:</b>\n"
        f"/switch - —Å–º–µ–Ω–∏—Ç—å –ø–µ—Ä—Å–æ–Ω–∞–∂–∞\n"
        f"/clear - –æ—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞\n"
        f"/model - –≤—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å (llm)\n\n"
        f"<b>‚è± –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º:</b>\n"
        f"/time_mode - –ø–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º\n"
        f"/recent - —Ç–æ–ª—å–∫–æ —Å–≤–µ–∂–∏–µ (2 –Ω–µ–¥–µ–ª–∏) üî•\n"
        f"/balanced - –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é) ‚öñÔ∏è\n"
        f"/historical - –≤—Å—è –∏—Å—Ç–æ—Ä–∏—è üìö\n"
        f"/date_range - –≤—ã–±—Ä–∞—Ç—å –ø–µ—Ä–∏–æ–¥ üìÖ",
        parse_mode="HTML"
    )
    await callback.answer()


@router.callback_query(F.data == "action:switch")
async def callback_switch(callback: CallbackQuery):
    """Handle switch action from menu."""
    speakers = get_available_speakers()
    await callback.message.edit_text(
        "–í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–≤–æ–≥–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞:",
        reply_markup=get_speaker_keyboard(speakers)
    )
    await callback.answer()


@router.callback_query(F.data == "action:clear")
async def callback_clear(callback: CallbackQuery):
    """Handle clear action from menu."""
    session = load_session(callback.from_user.id)
    session["history"] = []
    save_session(callback.from_user.id, session)

    await callback.message.edit_text("–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω–∞.")
    await callback.answer("–û—á–∏—â–µ–Ω–æ")


# Message handler
@router.message(F.text)
async def handle_message(message: Message):
    """Handle regular text messages."""
    # Start timing
    start_time = time.time()

    session = load_session(message.from_user.id)

    # Check if waiting for model selection
    if session.get("waiting_for_model", False):
        user_input = message.text.strip()

        # Validate input is a number
        if not user_input.isdigit():
            await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –Ω–æ–º–µ—Ä –º–æ–¥–µ–ª–∏ (1-4)")
            return

        choice = int(user_input)
        models = list(AVAILABLE_MODELS.keys())

        # Validate choice range
        if choice < 1 or choice > len(models):
            await message.answer(f"–ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä. –í—ã–±–µ—Ä–∏—Ç–µ –æ—Ç 1 –¥–æ {len(models)}")
            return

        # Save selected model
        selected_model = models[choice - 1]
        session["model"] = selected_model
        session["waiting_for_model"] = False
        save_session(message.from_user.id, session)

        model_name = AVAILABLE_MODELS[selected_model]
        await message.answer(f"‚úì –ú–æ–¥–µ–ª—å –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞: {model_name}")
        return

    # Check if waiting for date range input
    if session.get("waiting_for_dates", False):
        from datetime import datetime
        try:
            # Parse format "YYYY-MM-DD YYYY-MM-DD"
            dates = message.text.strip().split()
            if len(dates) != 2:
                raise ValueError("–ù—É–∂–Ω–æ 2 –¥–∞—Ç—ã")

            start_date = datetime.fromisoformat(dates[0]).date()
            end_date = datetime.fromisoformat(dates[1]).date()

            if start_date > end_date:
                raise ValueError("–ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ –ø–æ–∑–∂–µ –∫–æ–Ω–µ—á–Ω–æ–π")

            # Save to session
            session["time_filter"] = {
                "start": dates[0],
                "end": dates[1]
            }
            session["waiting_for_dates"] = False
            save_session(message.from_user.id, session)

            await message.answer(
                f"‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –¥–∏–∞–ø–∞–∑–æ–Ω:\n"
                f"üìÖ {dates[0]} ‚Äî {dates[1]}",
                parse_mode="HTML"
            )
            return

        except (ValueError, IndexError) as e:
            await message.answer(
                "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ:\n"
                "<code>YYYY-MM-DD YYYY-MM-DD</code>\n\n"
                "–ò–ª–∏ /cancel –¥–ª—è –æ—Ç–º–µ–Ω—ã",
                parse_mode="HTML"
            )
            return

    speaker = session.get("speaker")

    if not speaker:
        speakers = get_available_speakers()
        await message.answer(
            "–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞:",
            reply_markup=get_speaker_keyboard(speakers)
        )
        return

    # Show typing indicator
    await message.bot.send_chat_action(message.chat.id, "typing")

    user_input = message.text.strip()
    history = session.get("history", [])

    # Variables for logging
    rag_results = []
    response_text = ""
    error_msg = None

    # Search for context
    try:
        time_filter = session.get("time_filter", "balanced")
        rag_results = search(user_input, speaker=speaker, top_k=25, time_filter=time_filter)
        rag_context = format_search_results(rag_results, speaker=speaker)
    except Exception as e:
        print(f"Search error: {e}")
        rag_context = ""
        error_msg = f"RAG error: {str(e)}"

    # Build prompts
    system_prompt = build_system_prompt(speaker)
    user_prompt = build_user_prompt(rag_context, user_input, history)

    # Get LLM response
    try:
        # Get selected model from session (None = use default)
        model = session.get("model")
        # Run sync function in executor to not block
        loop = asyncio.get_event_loop()
        response_text = await loop.run_in_executor(
            None,
            lambda: chat(system_prompt, user_prompt, model=model)
        )
    except Exception as e:
        await message.answer(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
        error_msg = f"LLM error: {str(e)}"

        # Log error
        processing_time = (time.time() - start_time) * 1000
        logger = get_interaction_logger()
        logger.log_interaction(
            user_id=message.from_user.id,
            username=message.from_user.username,
            speaker=speaker,
            query=user_input,
            response="",
            rag_results=rag_results,
            llm_metadata={
                "model": session.get("model") or LLM_MODEL,
                "system_prompt_length": len(system_prompt),
                "user_prompt_length": len(user_prompt),
                "history_messages_count": len(history)
            },
            processing_time_ms=processing_time,
            error=error_msg
        )
        return

    # Update history
    history.append({"role": "user", "content": user_input})
    history.append({"role": "assistant", "content": response_text})

    # No limit on session storage - keep all history
    # if len(history) > 10:
    #     history = history[-10:]

    session["history"] = history
    save_session(message.from_user.id, session)

    # Log successful interaction
    processing_time = (time.time() - start_time) * 1000
    logger = get_interaction_logger()
    logger.log_interaction(
        user_id=message.from_user.id,
        username=message.from_user.username,
        speaker=speaker,
        query=user_input,
        response=response_text,
        rag_results=rag_results,
        llm_metadata={
            "model": session.get("model") or LLM_MODEL,
            "system_prompt_length": len(system_prompt),
            "user_prompt_length": len(user_prompt),
            "history_messages_count": len(history)
        },
        processing_time_ms=processing_time,
        error=None
    )

    await message.answer(response_text)
